{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eb65e3a-cec6-464a-b4c9-d657c048f3f1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2e75315912c1a1649b5f0daf8d8526a1",
     "grade": false,
     "grade_id": "cell-6423b43f63e98896",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# IS318 - Machine Learning\n",
    "\n",
    "## TP1 - Linear regression\n",
    "\n",
    "The goal of this TP is to experiment with linear regression and polynomial linear regression.\n",
    "\n",
    "First, we will work **without** the use of external libraries (such as `scikit-learn`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64a5a2b2-ef6b-4af6-8de0-e93c00052419",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8db2d123d60ab5c5c872b3b5f6df388c",
     "grade": false,
     "grade_id": "cell-8ce3af50a30c576b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b798d95-ee40-470c-9efe-6f73513acabe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f54357d640bdb3dc931efa0ff5d1a0b2",
     "grade": false,
     "grade_id": "cell-1a7c1f6d67f2f2c0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 1. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10f1001-e8c3-44fd-a7b6-db63519bfd58",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e5de1fe7d5aaae1875c4a69b0c08ca52",
     "grade": false,
     "grade_id": "cell-88e65b981197691f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let us generate data points from a relatively complicated function\n",
    "N = 100\n",
    "alpha, sigma = 2., 3.\n",
    "X = np.linspace(-3, 3, num=N)\n",
    "y = X + (alpha * np.sin((2. * np.pi * X) / sigma) * np.exp(-(X ** 2) / (sigma ** 2)))\n",
    "# Add some random noise\n",
    "rng = np.random.default_rng(42)\n",
    "y_noisy = y + rng.standard_normal(N) * 2.\n",
    "# Show the data points\n",
    "plt.plot(X, y_noisy, 'o')\n",
    "plt.plot(X, y)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2aee466-b495-4f4d-a2ca-739de04b8c8a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5cd8b11d173506d6c8c695215405c653",
     "grade": false,
     "grade_id": "cell-592514d0abb550f9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**(Question)** Shuffle and split the dataset into training (75%) and validation (25%) sets. Store the results into variables `X_train`, `y_train`, `X_valid`, `y_valid`.\n",
    "\n",
    "*Hint:* you can use `rng.permutation` to generate a random permutation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea383011",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5ac28a81d79677168b18c7867af37906",
     "grade": false,
     "grade_id": "train-valid-split",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(np.shape(X), np.shape(y_noisy))\n",
    "train_threshold = int(0.75*len(X))\n",
    "# print(train_threshold)\n",
    "\n",
    "stack = np.array([X,y_noisy,y])\n",
    "shuffeled_stack = rng.permutation(stack, axis=1)\n",
    "# print(stack)\n",
    "# print(\"=\"*20)\n",
    "# print(shuffeled_stack)\n",
    "\n",
    "X_train = shuffeled_stack[0][:train_threshold]\n",
    "y_train = shuffeled_stack[1][:train_threshold]\n",
    "\n",
    "X_valid = shuffeled_stack[0][train_threshold:]\n",
    "y_valid = shuffeled_stack[1][train_threshold:]\n",
    "\n",
    "print(np.shape(X_train),np.shape(y_train))\n",
    "print(np.shape(X_valid),np.shape(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a33f7b2-d77d-4a2b-b723-c1c9b707addc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2d40bc22a80eedcfce136a6136d71a94",
     "grade": true,
     "grade_id": "train-valid-split-tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert X_train.shape == (75,)\n",
    "assert y_train.shape == (75,)\n",
    "assert X_valid.shape == (25,)\n",
    "assert y_valid.shape == (25,)\n",
    "assert np.any(X_valid != X[75:]) # points should be shuffled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2d33dc-d3f2-4e79-814d-2a90a6b4aa09",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "80754b0c31ee2eeee212a89a87c2331a",
     "grade": false,
     "grade_id": "cell-a50781303dbb0b89",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 2. Linear regression in 1D\n",
    "\n",
    "Recall the 1D linear regression model, where we search for parameters $w_0, w_1$ that will satisfy $y_i = w_0 + w_1 x_i$ (for all $i$ in the training set).\n",
    "\n",
    "To simplify calculations, we usually set $\\textbf{w} = [w_0, w_1]^T$ and $\\textbf{x}_i = [1, x_i]^T$.\n",
    "\n",
    "Then we have $y_i = \\textbf{w}^T \\textbf{x}_i $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf33cae",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2375cb0786713962b9aac46a09c94784",
     "grade": false,
     "grade_id": "cell-00faf05cb395d4cb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**(Question)** Add a column with ones to the points in `X_train` and `X_valid`. Store the result in new variables `X_train_ones` and `X_valid_ones`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b254912c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "29817cde0841dbbfaeb339c7ea721300",
     "grade": true,
     "grade_id": "stack-one",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(X_train)\n",
    "X_train_ones = np.transpose(np.array([np.ones(len(X_train)),X_train]))\n",
    "X_valid_ones = np.transpose(np.array([np.ones(len(X_valid)),X_valid]))\n",
    "# print(X_valid_ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d97fd7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9b5c6a9eed69c0176b2f7c6ac179e958",
     "grade": false,
     "grade_id": "cell-e585b2cb96ff6c9f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**(Question)** Use normal equations to find the parameters that minimize the mean squared error on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13562da-c082-4e9f-b4e3-f989988bd6ab",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7febcd7c3a98df1b78caf6c2bb45ee34",
     "grade": false,
     "grade_id": "solve-w",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# The best weights are (X^TX)^{-1}X^Ty\n",
    "w = np.array(np.shape(X_train_ones))\n",
    "inv = np.linalg.inv(np.dot(np.transpose(X_train_ones),X_train_ones))\n",
    "weight = np.dot(inv, np.transpose(X_train_ones))\n",
    "w = np.dot(weight, y_train)\n",
    "\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb72d20d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aa41553e609fb4afac175ddf1298dd62",
     "grade": true,
     "grade_id": "solve-w-tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert w.shape == (2,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123c9e9c-e4b9-4365-a032-7cb72d045488",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4b4202a734c265891fef60d743866b21",
     "grade": false,
     "grade_id": "normal-equations-question",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "**(Question)** Is it always possible to apply this solution? Can you think of example situations where it might not work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cc53e9-3446-4135-8de4-67ba75f3eccf",
   "metadata": {},
   "source": [
    "This solution is only applicable in the case of linear regression and only if the matrix X^TX is inversable which means that all the features in the dataset are uncorelated and unrelated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870f4028",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bf49970b4cebcd562be0132db8792eb7",
     "grade": false,
     "grade_id": "plot-fit",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": true
    },
    "tags": []
   },
   "source": [
    "**(Question)** Plot the fitted line on top of the data points. Explain the result. (complete the code and comment in the cell below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e191cf0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c1a7cd1c8b02e6b8554e3a39e27b0be4",
     "grade": true,
     "grade_id": "cell-9fc189849b7c1c95",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(np.shape(X_train))\n",
    "plt.plot(X, [w[0]+x*w[1] for x in X], 'r--')\n",
    "plt.plot(X, y_noisy, 'bo')\n",
    "plt.plot(X, y, 'g')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f3fdbd-8e82-4a00-a6fc-7abe8f72f470",
   "metadata": {
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e1d6b77",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "89261e985bf1f12cd68da061812958d9",
     "grade": false,
     "grade_id": "plot-loss",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": true
    },
    "tags": []
   },
   "source": [
    "**(Question)** Plot the loss function landscape. What can you conclude from this visualization? (complete the code and comment in the cell below)\n",
    "\n",
    "*Hint: the loss landscape can be represented by a 2D map (for example of size 100x100) where in each coordinate $(w_0, w_1)$ the value is mean squared error for these parameters. You can use `plt.contourf` to visualize the result.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e92316",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0509691e6196b12131104986b413a489",
     "grade": true,
     "grade_id": "cell-5a7320a1abb19319",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def MSE(y_hat, y):\n",
    "    return np.sum((y - y_hat)**2)/len(y_hat)\n",
    "\n",
    "\n",
    "grid_size = 100\n",
    "\n",
    "_x = np.linspace(start=-5,stop=5,num=grid_size)\n",
    "_y = np.linspace(start=-5,stop=5,num=grid_size)\n",
    "_z = np.random.rand(grid_size, grid_size)\n",
    "# print(x)\n",
    "# _z = np.reshape(_z, (-1, grid_size))\n",
    "_x, _y = np.meshgrid(_x, _y)\n",
    "\n",
    "print(np.shape(_x),np.shape(_y),np.shape(_z))\n",
    "\n",
    "for i in range(grid_size):\n",
    "    for j in range(grid_size):\n",
    "        _z[i,j] = MSE([_x[i,j]+_y[i,j]*x for x in X_train], y_train)\n",
    "    \n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = plt.contourf(_x, _y, _z)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f070b78b",
   "metadata": {
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7a97e54",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "968e9d4eb788317fe97c6fa98d51cbb3",
     "grade": false,
     "grade_id": "cell-9d81b70df8d2f2fd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 3. Polynomial linear regression\n",
    "\n",
    "We move on the polynomial linear regression model with degree $D$, where the relationship between $y_i$ and $x_i$ is\n",
    "$ y_i = w_0 + w_1x_i + w_2x_i^2 + \\ldots + w_D x_i^D $\n",
    "\n",
    "With $\\textbf{w} = [w_0, \\ldots, w_D]^T$ and $\\textbf{x}_i = [1, x_i, x_i^2, \\ldots, x_i^D]^T$, we have $y_i = \\textbf{w}^T \\textbf{x}_i $.\n",
    "\n",
    "$D \\geq 1$ is an hyperparameter of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34b43a7-9665-4b23-b2d9-eef530f89faa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a7a358605f794eeb7b9a178469ec43bb",
     "grade": false,
     "grade_id": "cell-81be175807d22f40",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**(Question)** Complete the following `PolynomialRegression` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28079bb8-3bf3-4cde-8107-c71dff9a399b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "571a0e74677fee6e602a2539eb0d97f9",
     "grade": true,
     "grade_id": "polynomial-regression",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PolynomialRegression():\n",
    "    def __init__(self, D=1):\n",
    "        assert D >=1\n",
    "        self.D = D\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        '''Apply polynomial linear regression to fit `X` to `y`.\n",
    "        The result should be stored in an attribute `w`.'''\n",
    "        # print(X.shape)\n",
    "        X_ones = self.make_poly(X)\n",
    "        # print(y.shape)\n",
    "        self.w = np.empty((self.D, 1))\n",
    "        inv = np.linalg.inv(np.dot(np.transpose(X_ones),X_ones))\n",
    "        weight = np.dot(inv, np.transpose(X_ones))\n",
    "        self.w = np.dot(weight, y)\n",
    "        # print(f\"The shape of w is {self.w.shape}\")\n",
    "        \n",
    "    def predict(self, X):\n",
    "        '''Assuming the model has already been fit, return\n",
    "        predicted `y` values for given `X`.'''\n",
    "        X_ones = self.make_poly(X)\n",
    "        # print(np.shape(self.w), np.shape(X_ones))\n",
    "        y_pred = np.empty((len(X_ones),))\n",
    "        for i in range(len(X_ones)):\n",
    "            # print(f\"Dot product shapes {self.w.shape}x{X_ones[i].shape}\")\n",
    "            # print(f\"=={np.dot(np.transpose(self.w), X_ones[i]).shape}\")\n",
    "            y_pred[i] = np.dot(np.transpose(self.w), X_ones[i])\n",
    "            # print(y_pred)\n",
    "        return y_pred\n",
    "\n",
    "    def make_poly(self, X):\n",
    "        '''Augment a dataset of 1D points (vector of size N) to its\n",
    "        data matrix in polynomial form, including the zero column \n",
    "        (matrix of size N x D+1). Return the data matrix.'''\n",
    "        assert X.ndim == 1\n",
    "        X_ones = np.empty((len(X), self.D))\n",
    "        T = np.transpose(X_ones)\n",
    "        for d in range(self.D):\n",
    "            # print(f\"=={d}\")\n",
    "            # print(X[:3], np.power(X[:3], d))\n",
    "            T[d] =  np.power(X, d)\n",
    "        # print(T)\n",
    "        return np.transpose(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e86708c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "caaabea2ec7c465b326338f85b7b3830",
     "grade": false,
     "grade_id": "cell-134419d23b4fc5cd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**(Question)** Implement the mean squared error function to measure the quality of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a9c94b7",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f037b0820c1ecfdfe6d4e82568bfbf01",
     "grade": false,
     "grade_id": "mse",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mean_squared_error(y_true, y_pred):\n",
    "    '''Return the mean squared error between `y_true` and `y_pred`.'''\n",
    "    # print(f\"{y_true.shape} == {y_pred.shape}\")\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    return np.sum((y_true - y_pred)**2)/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e60be97a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c6a43c39fc1cfa77be1a21833fc5386b",
     "grade": true,
     "grade_id": "mse-tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a, b = np.random.randn(10), np.random.randn(10)\n",
    "assert mean_squared_error(a, b) >= 0.\n",
    "assert mean_squared_error(a, a) == 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f497eb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6f5d068c99a260e5f9a449f7e7514d21",
     "grade": false,
     "grade_id": "cell-efa1920e97836d98",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**(Question)** Apply the polynomial regression model with $D=5$. Compute and print the mean squared error for the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa711040",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0ec8b59c54094ddfea8303d421beb6a7",
     "grade": true,
     "grade_id": "apply-polyreg",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "poly_reg_5 = PolynomialRegression(5)\n",
    "poly_reg_5.fit(X_train, y_train)\n",
    "# print(np.shape(y_train), np.shape(poly_reg_5.predict(X_train)))\n",
    "print(mean_squared_error(y_train, poly_reg_5.predict(X_train)))\n",
    "print(mean_squared_error(y_valid, poly_reg_5.predict(X_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93453e6f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cd00c78f3c91ef7eb2bfcf0903155eb8",
     "grade": false,
     "grade_id": "plot-polyreg",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": true
    },
    "tags": []
   },
   "source": [
    "**(Question)** Plot the fitted polynomial curve on top of the data points. Explain the result. (complete the code and comment in the cell below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e873c6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4e31887b59bf417e843a006aead28342",
     "grade": true,
     "grade_id": "cell-850ac8c17b9b160a",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(np.shape(X_train))\n",
    "plt.plot(X, poly_reg_5.predict(X), 'r--')\n",
    "plt.plot(X, y_noisy, 'bo')\n",
    "plt.plot(X, y, 'g')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf75f7b1-c39c-41b8-9717-c4b8d61d05ac",
   "metadata": {
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c2a0d9a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4084752652a833d92ec16d124f122e82",
     "grade": false,
     "grade_id": "model-selection",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": true
    },
    "tags": []
   },
   "source": [
    "**(Question)** Using the validation set, implement a simple model selection strategy to optimize hyperparameter $D$ and print this value. For this question, you should limit the search to $D \\in [1, 15]$.\n",
    "To visualize potential underfitting and overfitting effects, plot the evolution of the error on the training and the validation sets for the different values of $D$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e971843-58fb-43e2-9d86-b8a263600d28",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd275b9b9db0e827b8c0fd6e54b5d11d",
     "grade": true,
     "grade_id": "cell-41640ccdf206336f",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "D = np.arange(start=1,stop=16)\n",
    "train_mse = []\n",
    "valid_mse = []\n",
    "for d in D:\n",
    "    poly_reg = PolynomialRegression(d)\n",
    "    poly_reg.fit(X_train, y_train)\n",
    "    train_mse.append(mean_squared_error(y_train, poly_reg.predict(X_train)))\n",
    "    valid_mse.append(mean_squared_error(y_valid, poly_reg.predict(X_valid)))\n",
    "\n",
    "\n",
    "plt.plot(D, train_mse, 'bo--')\n",
    "plt.plot(D, valid_mse, 'ro-')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006fc507",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "667ce4fb6c08f2bdf25deb104694054a",
     "grade": false,
     "grade_id": "model-selection-plot",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": true
    },
    "tags": []
   },
   "source": [
    "**(Question)** Plot the fitted polynomial curve of the best model on top of the data points. Comment the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7101773d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "642145dfb333b607ceb8f6327cb4700b",
     "grade": true,
     "grade_id": "cell-0bdafbf3133605ca",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(np.shape(X_train))\n",
    "poly_reg_9 = PolynomialRegression(9)\n",
    "poly_reg_9.fit(X_train, y_train)\n",
    "\n",
    "plt.plot(X, poly_reg_9.predict(X), 'r--')\n",
    "plt.plot(X, y_noisy, 'bo')\n",
    "plt.plot(X, y, 'g')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6c08a8-993d-4273-8235-d75adaa8e672",
   "metadata": {
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b62eef27",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c91dec77063c80e227ec871955ce3a4f",
     "grade": false,
     "grade_id": "cell-7e102b957010a338",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 4. Regularized polynomial regression\n",
    "\n",
    "Now, we want to implement polynomial regression with *weight decay* regularization:\n",
    "$\\hat{L}(\\textbf{w}) = \\frac{1}{N} \\lVert \\textbf{X} \\textbf{w} - \\textbf{y} \\rVert^2 + \\lambda \\lVert\\textbf{w}\\rVert^2$\n",
    "\n",
    "Here, $\\lambda \\geq 0$ is another hyperparameter of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36924b2-cfb1-478d-8afc-0578f209408f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f38f56b968985daedf38995031e67558",
     "grade": false,
     "grade_id": "cell-de3277f460f5b4ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(Question)** Complete the following `RegularizedPolynomialRegression` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a371d80b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "56dc626b44cc0d682701a47a456c45bc",
     "grade": true,
     "grade_id": "polyreg-regularized",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RegularizedPolynomialRegression():\n",
    "    def __init__(self, D=1, lmbda=1.):\n",
    "        assert D >=1 and lmbda >= 0.\n",
    "        self.D = D\n",
    "        self.lmbda = lmbda\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        '''Apply polynomial linear regression to fit `X` to `y`.\n",
    "        The result should be stored in an attribute `w`.'''\n",
    "        X_ones = self.make_poly(X)\n",
    "        # print(y.shape)\n",
    "        self.w = np.empty((self.D, 1))\n",
    "        decay = self.lmbda*np.identity(self.D)\n",
    "        inv = np.linalg.inv(np.add(decay, np.dot(np.transpose(X_ones),X_ones)))\n",
    "        weight = np.dot(inv, np.transpose(X_ones))\n",
    "        self.w = np.dot(weight, y)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        '''Assuming the model has already been fit, return\n",
    "        predicted `y` values for given `X`.'''\n",
    "        X_ones = self.make_poly(X)\n",
    "        # print(np.shape(self.w), np.shape(X_ones))\n",
    "        y_pred = np.empty((len(X_ones),))\n",
    "        for i in range(len(X_ones)):\n",
    "            # print(f\"Dot product shapes {self.w.shape}x{X_ones[i].shape}\")\n",
    "            # print(f\"=={np.dot(np.transpose(self.w), X_ones[i]).shape}\")\n",
    "            y_pred[i] = np.dot(np.transpose(self.w), X_ones[i])\n",
    "            # print(y_pred)\n",
    "        return y_pred\n",
    "\n",
    "    def make_poly(self, X):\n",
    "        '''Augment a dataset of 1D points (vector of size N) to its\n",
    "        data matrix in polynomial form, including the zero column \n",
    "        (matrix of size N x D+1). Return the data matrix.'''\n",
    "        assert X.ndim == 1\n",
    "        X_ones = np.empty((len(X), self.D))\n",
    "        T = np.transpose(X_ones)\n",
    "        for d in range(self.D):\n",
    "            T[d] =  np.power(X, d)\n",
    "        return np.transpose(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5a876e-aba2-48c3-ba84-5a2e9404b223",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d91fae5b44860437ba4925f2086c36a9",
     "grade": false,
     "grade_id": "cell-103fd01e4f18bd87",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": true
    },
    "tags": []
   },
   "source": [
    "**(Question)** Apply regularized linear regression and play around with hyperparameters $D$ and $\\lambda$. Plot the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dcffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(X_train))\n",
    "poly_reg_9 = RegularizedPolynomialRegression(11,2)\n",
    "poly_reg_9.fit(X_train, y_train)\n",
    "\n",
    "plt.plot(X, poly_reg_9.predict(X), 'r--')\n",
    "plt.plot(X, y_noisy, 'bo')\n",
    "plt.plot(X, y, 'g')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fe896e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5f5eae1bc71edbe859dacfc8885fca39",
     "grade": true,
     "grade_id": "apply-polyreg-regularized",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lamb = np.arange(start=0,stop=6)\n",
    "train_mse = []\n",
    "valid_mse = []\n",
    "for l in lamb:\n",
    "    poly_reg = RegularizedPolynomialRegression(11,l)\n",
    "    poly_reg.fit(X_train, y_train)\n",
    "    train_mse.append(mean_squared_error(y_train, poly_reg.predict(X_train)))\n",
    "    valid_mse.append(mean_squared_error(y_valid, poly_reg.predict(X_valid)))\n",
    "\n",
    "\n",
    "plt.plot(train_mse, 'bo--', label=\"train\")\n",
    "plt.plot(valid_mse, 'ro-', label=\"valid\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df4cb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = np.arange(start=1,stop=16)\n",
    "\n",
    "\n",
    "train_mse = []\n",
    "valid_mse = []\n",
    "for d in D:\n",
    "    poly_reg = PolynomialRegression(d)\n",
    "    poly_reg.fit(X_train, y_train)\n",
    "    train_mse.append(mean_squared_error(y_train, poly_reg.predict(X_train)))\n",
    "    valid_mse.append(mean_squared_error(y_valid, poly_reg.predict(X_valid)))\n",
    "\n",
    "\n",
    "plt.plot(D, train_mse, 'ro--', label=\"train\")\n",
    "plt.plot(D, valid_mse, 'ro-', label=\"valid\")\n",
    "\n",
    "\n",
    "train_mse = []\n",
    "valid_mse = []\n",
    "for d in D:\n",
    "    poly_reg = RegularizedPolynomialRegression(d,2)\n",
    "    poly_reg.fit(X_train, y_train)\n",
    "    train_mse.append(mean_squared_error(y_train, poly_reg.predict(X_train)))\n",
    "    valid_mse.append(mean_squared_error(y_valid, poly_reg.predict(X_valid)))\n",
    "\n",
    "\n",
    "plt.plot(D, train_mse, 'go--', label=\"train_decay\")\n",
    "plt.plot(D, valid_mse, 'go-', label=\"valid_decay\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bd5618",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6a9791858a9681769a35da95bb0a2869",
     "grade": false,
     "grade_id": "cell-3f87566482994138",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 5. Comparison with `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b019657b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5f39768d5d809efe729c6348b425f9c1",
     "grade": false,
     "grade_id": "cell-2214d7d896066539",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e22cfd9-90c9-4ba5-949e-c4364c4f5901",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "19ce745d956bfe4057a36c4df7af9bc6",
     "grade": false,
     "grade_id": "sklearn-comparison",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": true
    },
    "tags": []
   },
   "source": [
    "**(Question)** Use the `sklearn` classes imported above to apply polynomial regression on our toy dataset. Compare the results with your implementation and comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c22765",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae98694413091539f1dab415f676c189",
     "grade": true,
     "grade_id": "cell-0aa9e5838da9ea0c",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PolynomialFeatures((0,11))\n",
    "\n",
    "linear_reg = LinearRegression()\n",
    "\n",
    "linear_reg.fit(X_train, y_train)\n",
    "print(f\"shapes{X_train.shape} and {y_train.shape}\")\n",
    "print(linear_reg.score(X_valid, y_valid))\n",
    "\n",
    "y_pred = linear_reg.predict(X_valid) \n",
    "plt.scatter(X_valid, y_valid, color ='b') \n",
    "plt.plot(X_valid, y_pred, color ='k') \n",
    "  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8bffd3-3198-4c94-9c9f-40b38043cec4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
